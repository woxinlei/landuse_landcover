import os
import numpy as np
from osgeo import gdal
import pandas as pd

def extract_pixel_ndvi_cluster(ndvi_folder, cluster_folder, output_csv_path):
    """
    ä» NDVI å’Œèšç±» TIF å›¾ä¸­æå–æ¯ä¸ªåƒç´ çš„èšç±» IDã€NDVI å€¼å’Œæ—¶é—´æˆ³ï¼Œå¹¶ä¿å­˜ä¸º CSVã€‚

    å‚æ•°:
    - ndvi_folder: å­˜æ”¾ NDVI ç»“æœçš„æ–‡ä»¶å¤¹è·¯å¾„
    - cluster_folder: å­˜æ”¾å¯¹åº”èšç±»å›¾çš„æ–‡ä»¶å¤¹è·¯å¾„
    - output_csv_path: è¾“å‡º CSV æ–‡ä»¶å®Œæ•´è·¯å¾„
    """
    ndvi_files = [
        os.path.join(ndvi_folder, f)
        for f in os.listdir(ndvi_folder)
        if f.endswith("_ndvi_results.tif")
    ]

    all_rows = []

    for ndvi_fp in ndvi_files:
        basename = os.path.basename(ndvi_fp)
        parts = basename.split("_")
        if len(parts) < 7:
            continue
        timestamp = f"{parts[3]}_{parts[4]}"

        cluster_name = basename.replace("_ndvi_results.tif", "_supervised_kmeans_no_city.tif")
        cluster_fp = os.path.join(cluster_folder, cluster_name)

        if not os.path.exists(cluster_fp):
            print(f"âš ï¸ è·³è¿‡æœªæ‰¾åˆ°èšç±»æ–‡ä»¶: {cluster_fp}")
            continue

        ndvi_ds = gdal.Open(ndvi_fp)
        cluster_ds = gdal.Open(cluster_fp)
        ndvi = ndvi_ds.GetRasterBand(1).ReadAsArray().astype(np.float32)
        cluster = cluster_ds.GetRasterBand(1).ReadAsArray().astype(np.int32)

        rows, cols = ndvi.shape
        for i in range(rows):
            for j in range(cols):
                c = cluster[i, j]
                v = ndvi[i, j]
                if c == 0 or not (-1 <= v <= 1):  # è¿‡æ»¤æ— æ•ˆå€¼
                    continue
                all_rows.append({
                    "row": i,
                    "col": j,
                    "cluster_id": c,
                    "timestamp": timestamp,
                    "ndvi_value": v
                })

    # ä¿å­˜ä¸º DataFrame
    df = pd.DataFrame(all_rows)
    df.to_csv(output_csv_path, index=False)
    print(f"âœ… å·²ä¿å­˜åƒç´ çº§èšç±»-NDVIè¡¨æ ¼ï¼Œå…±è®°å½•æ¡æ•°ï¼š{len(df)}")

def clean_cluster_data(input_csv_path, output_csv_path, valid_clusters=[1, 2, 3, 4]):
    """
    æ¸…æ´—åƒç´ çº§èšç±» NDVI æ•°æ®ï¼Œåªä¿ç•™æŒ‡å®š cluster_id çš„è®°å½•ã€‚

    å‚æ•°:
    - input_csv_path: è¾“å…¥çš„åŸå§‹ CSV æ–‡ä»¶è·¯å¾„
    - output_csv_path: æ¸…æ´—å CSV æ–‡ä»¶çš„ä¿å­˜è·¯å¾„
    - valid_clusters: ä¿ç•™çš„ cluster_id åˆ—è¡¨ï¼Œé»˜è®¤æ˜¯ [1, 2, 3, 4]
    """
    if not os.path.exists(input_csv_path):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_csv_path}")
        return

    # è¯»å–æ•°æ®
    df = pd.read_csv(input_csv_path)

    # åªä¿ç•™æŒ‡å®š cluster_id çš„è®°å½•
    df_cleaned = df[df['cluster_id'].isin(valid_clusters)]

    # ä¿å­˜ç»“æœ
    df_cleaned.to_csv(output_csv_path, index=False)
    print(f"âœ… å·²å®Œæˆæ¸…æ´—ï¼Œä»…ä¿ç•™ cluster_id ä¸º {valid_clusters} çš„æ•°æ®ï¼Œå…± {len(df_cleaned)} æ¡è®°å½•")
# âœ… å‡½æ•°åº”æ”¾åœ¨å¤–éƒ¨ï¼Œä¾›ä¸»å‡½æ•°è°ƒç”¨
def assign_land_type(group):
    ranked = group.sort_values(by='ndvi_mean', ascending=False).copy()
    initial_land_types = ['æ—åœ°', 'è€•åœ°', 'å¾…è€•åœ°', 'è£¸åœ°']
    ranked['land_type'] = initial_land_types[:len(ranked)]

    idx = ranked.index.tolist()

    # ğŸ“Œ è‡ªå®šä¹‰è§„åˆ™
    if ranked.loc[idx[0], 'ndvi_mean'] < 0.2:
        ranked.loc[idx[0], 'land_type'] = 'å¾…è€•åœ°'
    if ranked.loc[idx[1], 'ndvi_mean'] < 0.2:
        ranked.loc[idx[1], 'land_type'] = 'å¾…è€•åœ°'
    if ranked.loc[idx[2], 'ndvi_mean'] > 0.25:
        ranked.loc[idx[2], 'land_type'] = 'è€•åœ°'
    if ranked.loc[idx[3], 'ndvi_mean'] > 0.25:
        ranked.loc[idx[3], 'land_type'] = 'è€•åœ°'

    print(f"\nğŸ“… Timestamp: {group['timestamp'].iloc[0]}")
    print(ranked[['cluster_id', 'ndvi_mean', 'ndvi_max', 'ndvi_min', 'ndvi_std', 'ndvi_amp', 'ndvi_median', 'land_type']])

    return ranked

# âœ… ä¸»å‡½æ•°
def classify_land_types_from_ndvi(csv_input_path, csv_output_path):
    df = pd.read_csv(csv_input_path)
    df['date'] = pd.to_datetime(df['timestamp'].str.split('_').str[0], format="%Y%m%d")

    grouped = df.groupby(['timestamp', 'cluster_id'])['ndvi_value'].agg(
        ndvi_median='median', 
        ndvi_mean='mean',
        ndvi_max='max',
        ndvi_min='min',
        ndvi_std='std',
        ndvi_amp=lambda x: x.max() - x.min()
    ).reset_index()

    grouped_labeled = grouped.groupby('timestamp').apply(assign_land_type).reset_index(drop=True)

    df = df.merge(grouped_labeled[['timestamp', 'cluster_id', 'land_type']],
                  on=['timestamp', 'cluster_id'], how='left')

    df.to_csv(csv_output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… åœ°ç‰©åˆ†ç±»å®Œæˆï¼Œç»“æœä¿å­˜è‡³ï¼š{csv_output_path}")

def correct_land_type_sequence(land_types):
    """æŒ‰è§„åˆ™ä¿®æ­£æ—¶é—´åºåˆ—ä¸­çš„åœ°ç‰©ç±»å‹"""
    bare_like = {'è£¸åœ°', 'å¾…è€•åœ°'}
    veg_like = {'è€•åœ°', 'æ—åœ°'}

    corrected_types = []
    has_bare = any(lt in bare_like for lt in land_types)
    has_veg = any(lt in veg_like for lt in land_types)

    # å¦‚æœå…¨æ˜¯è£¸åœ°æˆ–å¾…è€•åœ°ï¼Œåˆ™å…¨éƒ¨è®¾ä¸ºè£¸åœ°
    if all(lt in bare_like for lt in land_types):
        return ['è£¸åœ°'] * len(land_types)

    for lt in land_types:
        if has_bare and lt == 'æ—åœ°':
            corrected_types.append('è€•åœ°')
        elif has_veg and lt in bare_like:
            corrected_types.append('å¾…è€•åœ°')
        else:
            corrected_types.append(lt)
    return corrected_types

def apply_land_type_correction(input_path, output_path):
    
    """è¯»å–åƒç´ çº§NDVIåœ°ç‰©ç±»å‹ï¼ŒæŒ‰æ—¶é—´åºåˆ—è¿›è¡Œåœ°ç‰©ä¿®æ­£"""

    print("ğŸ“¥ æ­£åœ¨è¯»å–åŸå§‹æ•°æ®...")
    df = pd.read_csv(input_path)

    # åªä¿ç•™æˆ‘ä»¬å…³å¿ƒçš„ç±»åˆ«
    df = df[df['land_type'].isin(['æ—åœ°', 'è€•åœ°', 'è£¸åœ°', 'å¾…è€•åœ°'])]

    # è½¬æ¢ä¸ºæ—¶é—´æˆ³ä¾¿äºæ’åº
    df['timestamp'] = pd.to_datetime(df['timestamp'].str.split("_").str[0], format="%Y%m%d")

    # å¦‚æœè¾“å‡ºæ–‡ä»¶å­˜åœ¨åˆ™åˆ é™¤
    if os.path.exists(output_path):
        os.remove(output_path)

    # å†™å…¥è¡¨å¤´
    df.head(0).assign(corrected_type='').to_csv(output_path, index=False, encoding='utf-8-sig')

    grouped = df.groupby(['row', 'col'])
    total = len(grouped)
    print(f"ğŸ§© å…±éœ€å¤„ç†åƒç´ ç‚¹ï¼š{total}")
    count = 0

    for (row, col), group in grouped:
        group = group.sort_values("timestamp")
        land_types = list(group['land_type'])

        corrected = correct_land_type_sequence(land_types)
        group['corrected_type'] = corrected

        # è¿½åŠ å†™å…¥
        group.to_csv(output_path, mode='a', header=False, index=False, encoding='utf-8-sig')

        count += 1
        if count % 1000 == 0 or count == total:
            print(f"âœ… å·²å¤„ç† {count}/{total} ä¸ªåƒç´ ç‚¹...")

    print("\nğŸ‰ ä¿®æ­£å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š", output_path)
def classify_crop_types(input_path, output_path):
    """æ ¹æ®æ—¶é—´åºåˆ— NDVI ç±»åˆ«è¿›è¡Œä½œç‰©/æ—åœ°ä¿®æ­£åˆ†ç±»"""

    df = pd.read_csv(input_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df = df[['row', 'col', 'timestamp', 'corrected_type', 'ndvi_value']]
    df['month'] = df['timestamp'].dt.month

    grouped = df.groupby(['row', 'col'])

    if os.path.exists(output_path):
        os.remove(output_path)

    first_write = True
    total = len(grouped)

    for i, ((row, col), group) in enumerate(grouped):
        if i % 1000 == 0 or i == total - 1:
            print(f"ğŸ“ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{total} ä¸ªåƒç´ ç‚¹ï¼šrow={row}, col={col}")

        group = group.sort_values('timestamp').copy()
        types = group['corrected_type'].tolist()
        months = group['month'].tolist()
        timestamps = group['timestamp'].tolist()

        # === Step 1ï¼šæ—åœ°åˆ¤æ–­ ===
        growing_season = [(4 <= m <= 9) for m in months]
        types_in_growing = [t for t, cond in zip(types, growing_season) if cond]
        is_forest = (
            any(t in {'è€•åœ°', 'æ—åœ°'} for t in types_in_growing) and
            all(t not in {'è£¸åœ°', 'å¾…è€•åœ°'} for t in types_in_growing)
        )
        if is_forest:
            types = ['æ—åœ°' if t == 'è€•åœ°' else t for t in types]

        # === Step 2ï¼šä½œç‰©åˆ†ç±» ===
        wheat_cutoff = rice_cutoff = second_wheat_start_ts = None

        for lt, m, ts in zip(types, months, timestamps):
            if lt in {'è£¸åœ°', 'å¾…è€•åœ°'} and m in {5, 6} and wheat_cutoff is None:
                wheat_cutoff = ts
            if lt in {'è£¸åœ°', 'å¾…è€•åœ°'} and m in {9, 10} and rice_cutoff is None:
                rice_cutoff = ts
        for lt, m, ts in zip(types, months, timestamps):
            if lt in {'è£¸åœ°', 'å¾…è€•åœ°'} and m in {9, 10, 11}:
                second_wheat_start_ts = ts
                break

        new_types = []
        for lt, m, ts in zip(types, months, timestamps):
            if lt == 'è€•åœ°':
                if wheat_cutoff and ts < wheat_cutoff and m <= 6:
                    new_types.append('å°éº¦')
                elif rice_cutoff and ts < rice_cutoff and 7 <= m <= 10:
                    new_types.append('æ°´ç¨»')
                elif second_wheat_start_ts and ts > second_wheat_start_ts:
                    new_types.append('å°éº¦')
                else:
                    new_types.append('è€•åœ°')
            else:
                new_types.append(lt)

        group['corrected_type'] = new_types
        group.to_csv(output_path, mode='a', index=False, encoding='utf-8-sig', header=first_write)
        first_write = False

    print("\nğŸ¯ ä½œç‰©ä¸æ—åœ°ç±»å‹å·²è¯†åˆ«å®Œæ¯•ï¼Œè¾“å‡ºæ–‡ä»¶ä½äºï¼š", output_path)

